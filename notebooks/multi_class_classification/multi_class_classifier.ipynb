{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ee9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, precision_recall_curve\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6d9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_FASTTEXT_MODEL = os.getcwd() + '/../../models/lid.176.bin'\n",
    "LANG_EN = \"__label__en\"\n",
    "LANG_DE = \"__label__de\"\n",
    "\n",
    "fasttext.FastText.eprint = lambda x: None\n",
    "fasttext_model = fasttext.load_model(PRETRAINED_FASTTEXT_MODEL)\n",
    "\n",
    "def detect_language(text):\n",
    "    \n",
    "    lang_label = fasttext_model.predict(text)[0][0].split('__label__')[1]\n",
    "    return lang_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "88fcd4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ko'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"미소와 함께 '일상의 변화'를 만들 '미소 메이커스'를 찾습니다  미소는 국내 No.1 O2O 홈서비스 플랫폼 기업입니다. \"Hotel-like service in your home\"  이라는 비전 아래, 고객에게 더욱 행복한 경험을 더욱 많이 제공하고자 합니다. 대표 서비스인 '홈클리닝'을 중심으로, '이사'/'가전청소'/'인테리어'/'펫시팅' 등  70여가지의 서비스 로 사업 범위를 확장하였습니다. 고객 만족 원칙과 데이터 기반 기술로 매년 2배가량 돋보이게 성장하고 있습니다. 2021년 현재 Series A 단계이며, 총 투자규모는 약 130억 원입니다. 한국 O2O 기업으로는 최초로 실리콘밸리의 최대 벤처 투자사 ‘Y Combinator’로부터 31억 원의 투자를 유치했습니다. 누적 매출액은  1,000억 원 , 누적 주문건수  300만 건  및 누적 파트너수  40,000명 을 돌파했습니다.  미소의 일 하는 방식 엿보기 Work hard on the Right Things 미소는 올바른 일에 집중합니다. 미소 팀블로그에서 미소 메이커스의 이야기를 들어 보세요!    예비 미소 메이커스를 위한 참고 사이트   채용과 관련한 모든 문의사항은,  recruit@getmiso.com (People Team) 으로 부탁드립니다.\"\"\"\n",
    "fasttext_model.predict(text)[0][0].split('__label__')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed70b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.LoadOptions(\n",
    "    allow_partial_checkpoint=False,\n",
    "    experimental_io_device='/job:localhost',\n",
    "    experimental_skip_checkpoint=False\n",
    ")\n",
    "\n",
    "tf_model = tf.keras.models.load_model(\n",
    "    os.getcwd() + '/../../models/USE_model/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd58b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_classifier():\n",
    "    return SVC(kernel='rbf', gamma='auto', class_weight='balanced', probability=True, random_state=122)\n",
    "\n",
    "def get_rf_classifier():\n",
    "    return RandomForestClassifier(n_estimators=300, random_state=122)\n",
    "\n",
    "def get_lr_classifier():\n",
    "    return LogisticRegression(class_weight='balanced', random_state=122)\n",
    "\n",
    "def get_three_class_models():\n",
    "    \n",
    "    model_1 = get_svm_classifier()\n",
    "    model_2 = get_svm_classifier()\n",
    "    model_3 = get_lr_classifier()\n",
    "    \n",
    "    return [model_1, model_2, model_3]\n",
    "\n",
    "def get_modified_vectors(vec_data):\n",
    "    \n",
    "    new_data = []\n",
    "    for val in vec_data:\n",
    "        new_data.append(val)\n",
    "    \n",
    "    new_data = np.array(new_data).reshape(-1, 512)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d22d27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_output(preds, threshold):\n",
    "    \n",
    "    y_preds = []\n",
    "    for val in preds:\n",
    "        if val >= threshold:\n",
    "            y_preds.append(1)\n",
    "        else:\n",
    "            y_preds.append(0)\n",
    "        \n",
    "    y_preds = np.array(y_preds)\n",
    "    \n",
    "    return y_preds\n",
    "\n",
    "def get_f1_score_binary(y, preds, threshold, print_report=False):\n",
    "    \n",
    "    y_preds = get_threshold_output(preds, threshold)\n",
    "    if print_report:\n",
    "        print(classification_report(y, y_preds))\n",
    "    \n",
    "    metrics = precision_recall_fscore_support(y, y_preds)\n",
    "    f1_score_tech = metrics[2][1]\n",
    "    \n",
    "    return f1_score_tech\n",
    "\n",
    "def get_best_threshold(y, preds):\n",
    "    \n",
    "    threshold_vals = np.arange(0.1, 1, 0.001)\n",
    "    f1_score_list = []\n",
    "    \n",
    "    for val in threshold_vals:\n",
    "        f1_score_list.append(get_f1_score_binary(y, preds, val))\n",
    "\n",
    "    max_idx = np.nanargmax(f1_score_list)\n",
    "    thre_max = threshold_vals[max_idx]\n",
    "    fscore = f1_score_list[max_idx]\n",
    "    \n",
    "    print(fscore)\n",
    "    print(thre_max)\n",
    "    \n",
    "    return thre_max    \n",
    "\n",
    "def get_trained_model_binary(X, y):\n",
    "    \n",
    "#     skf_f1score = perform_cross_validation(X, y, fold_cnt=5)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=123)\n",
    "    \n",
    "    model = get_svm_classifier()\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), model)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "    threshold = get_best_threshold(y_test, pred_probs)\n",
    "    \n",
    "    skf_f1score = 0\n",
    "    \n",
    "    return clf, skf_f1score, threshold\n",
    "\n",
    "def get_test_f1score_binary(model, X_test, y_test, threshold):\n",
    "    \n",
    "    preds = model.predict_proba(X_test)\n",
    "    preds = preds[:,1]\n",
    "\n",
    "    f1_score = get_f1_score_binary(y_test, preds, threshold, print_report=True)\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22cedd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_class_metrics(y_test, preds, pr_flag=False):\n",
    "    \n",
    "    metrics = precision_recall_fscore_support(y_test, preds)\n",
    "    \n",
    "    f1_score_tech = metrics[2][1]\n",
    "    f1_score_milt = metrics[2][2]\n",
    "#     f1_score_milt = metrics[2][1]\n",
    "    \n",
    "    f1_score = (f1_score_tech+f1_score_milt)/2\n",
    "    \n",
    "    if pr_flag:\n",
    "        print(classification_report(y_test, preds))\n",
    "        return f1_score, preds\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "def perform_cross_validation(X, y, fold_cnt=5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=fold_cnt, shuffle=True, random_state=123)\n",
    "    f1_scores_list = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model = get_svm_classifier()\n",
    "        clf = make_pipeline(StandardScaler(with_mean=False), model)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "\n",
    "        f1_score = get_multi_class_metrics(y_test, preds, pr_flag=False)\n",
    "        f1_scores_list.append(f1_score)\n",
    "    \n",
    "    return sum(f1_scores_list)/fold_cnt\n",
    "\n",
    "def get_trained_model(X, y):\n",
    "    \n",
    "    skf_f1score = perform_cross_validation(X, y, fold_cnt=5)\n",
    "    \n",
    "    model = get_svm_classifier()\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), model)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf, skf_f1score\n",
    "\n",
    "def get_test_f1score(model, X_test, y_test):\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    f1_score, preds = get_multi_class_metrics(y_test, preds, pr_flag=True)\n",
    "    \n",
    "    return f1_score, preds\n",
    "\n",
    "def get_performance_metrics(X_train, y_train, X_test, y_test, binary=False):\n",
    "    \n",
    "    if binary:\n",
    "        model, cv_score, threshold = get_trained_model_binary(X_train, y_train)\n",
    "        test_f1_score = get_test_f1score_binary(model, X_test, y_test,threshold)\n",
    "        \n",
    "        return model, threshold\n",
    "    else:    \n",
    "        model, cv_score = get_trained_model(X_train, y_train)\n",
    "        test_f1_score, preds = get_test_f1score(model, X_test, y_test)\n",
    "        \n",
    "        test_df['pred_label'] = preds\n",
    "\n",
    "        \n",
    "        return model\n",
    "\n",
    "    print()\n",
    "    print(f'Training CV f1 score: {cv_score}')\n",
    "    print(f'Test F1-score: {test_f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff0199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(os.getcwd() + '/../dataframes/train_df_features.pkl')  ## train_df\n",
    "test_df = pd.read_pickle(os.getcwd() + '/../dataframes/test_df_features.pkl') ## test_df\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61f3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = pd.read_pickle(os.getcwd() + '/../dataframes/unlabeled_df_features.pkl') # unlabeled_df\n",
    "# unlabeled_df['lang'] = unlabeled_df.apply(lambda x:detect_language(x['text'].revplace(\"\\n\",\" \")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d6b26a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>doc_vec</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>nc_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210705_news_466581.txt</td>\n",
       "      <td>Whilst residing in Paris in the sixth century,...</td>\n",
       "      <td>[[0.0117851915, -0.013124656, 0.006891161, 0.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>([Paris, the sixth century, the widow, the mer...</td>\n",
       "      <td>[[-0.0061701364, -0.012984723, -0.02264499, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210705_news_466582.txt</td>\n",
       "      <td>Early in 2018, the volcano Anak Krakatau in In...</td>\n",
       "      <td>[[-0.011649534, -0.033309218, -0.004555769, 0....</td>\n",
       "      <td>en</td>\n",
       "      <td>([the volcano Anak Krakatau, Indonesia, it, a ...</td>\n",
       "      <td>[[-0.0047265957, -0.011267428, -0.01635613, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210705_news_466583.txt</td>\n",
       "      <td>Posted by Cassidy Curtis, Visual Designer and ...</td>\n",
       "      <td>[[-0.07128145, 0.011230298, 0.045890186, -0.07...</td>\n",
       "      <td>en</td>\n",
       "      <td>([Cassidy Curtis, Visual Designer, David Sales...</td>\n",
       "      <td>[[-0.005185811, -0.0008352126, -0.010343001, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210705_news_466584.txt</td>\n",
       "      <td>One thing I love about living in Germany is th...</td>\n",
       "      <td>[[-0.012562483, -0.03460731, 0.089639775, 0.02...</td>\n",
       "      <td>en</td>\n",
       "      <td>([one thing, I, Germany, the bread, American W...</td>\n",
       "      <td>[[0.005709256, -0.015197817, -0.002575722, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210705_news_466585.txt</td>\n",
       "      <td>Embrace the Grind There’s this card trick I sa...</td>\n",
       "      <td>[[-0.04854836, 0.07415119, 0.044061035, -0.008...</td>\n",
       "      <td>en</td>\n",
       "      <td>([the Grind, this card trick, I, I, all the ti...</td>\n",
       "      <td>[[0.0018794591, -0.0019065727, -0.024219586, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>210705_news_469717.txt</td>\n",
       "      <td>Und weshalb sollte die Union jetzt auf den stä...</td>\n",
       "      <td>[[-0.032125708, 0.005915861, 0.03515286, 0.006...</td>\n",
       "      <td>de</td>\n",
       "      <td>([der Union, der stark Kandidat, der Furcht, d...</td>\n",
       "      <td>[[-0.004311784, -0.00028916707, -0.020514684, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>210705_news_469718.txt</td>\n",
       "      <td>Ars Technica   Today's Dealmaster includes a r...</td>\n",
       "      <td>[[0.045911647, 0.0021237172, -0.056985255, 0.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>([Ars Technica, today's Dealmaster, a return, ...</td>\n",
       "      <td>[[-0.013846245, 0.010529164, -0.007516246, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>210705_news_469719.txt</td>\n",
       "      <td>Enlarge   /  A Yemeni khamsiyat (top left), a ...</td>\n",
       "      <td>[[0.027108321, -0.004789675, -0.036533337, 0.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>([a yemeni khamsiyat, a spanish real, (top rig...</td>\n",
       "      <td>[[0.008365323, -0.019968145, -0.02338454, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>210705_news_469722.txt</td>\n",
       "      <td>Bridgerton , the raunchy Regency costume drama...</td>\n",
       "      <td>[[-0.0044380925, 0.0010670775, 0.06688552, 0.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>([Bridgerton, the raunchy Regency costume dram...</td>\n",
       "      <td>[[-0.011590819, -0.006641924, -0.014274846, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>210705_news_469723.txt</td>\n",
       "      <td>The hunt for a serial killer who preyed on gay...</td>\n",
       "      <td>[[0.0336337, -0.0058375876, 0.08533424, 0.0237...</td>\n",
       "      <td>en</td>\n",
       "      <td>([the hunt, a serial killer, who, gay man, Tor...</td>\n",
       "      <td>[[-0.0049721645, 0.00051928655, -0.0070937215,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1809 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "0     210705_news_466581.txt   \n",
       "1     210705_news_466582.txt   \n",
       "2     210705_news_466583.txt   \n",
       "3     210705_news_466584.txt   \n",
       "4     210705_news_466585.txt   \n",
       "...                      ...   \n",
       "1805  210705_news_469717.txt   \n",
       "1806  210705_news_469718.txt   \n",
       "1807  210705_news_469719.txt   \n",
       "1808  210705_news_469722.txt   \n",
       "1809  210705_news_469723.txt   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Whilst residing in Paris in the sixth century,...   \n",
       "1     Early in 2018, the volcano Anak Krakatau in In...   \n",
       "2     Posted by Cassidy Curtis, Visual Designer and ...   \n",
       "3     One thing I love about living in Germany is th...   \n",
       "4     Embrace the Grind There’s this card trick I sa...   \n",
       "...                                                 ...   \n",
       "1805  Und weshalb sollte die Union jetzt auf den stä...   \n",
       "1806  Ars Technica   Today's Dealmaster includes a r...   \n",
       "1807  Enlarge   /  A Yemeni khamsiyat (top left), a ...   \n",
       "1808  Bridgerton , the raunchy Regency costume drama...   \n",
       "1809  The hunt for a serial killer who preyed on gay...   \n",
       "\n",
       "                                                doc_vec lang  \\\n",
       "0     [[0.0117851915, -0.013124656, 0.006891161, 0.0...   en   \n",
       "1     [[-0.011649534, -0.033309218, -0.004555769, 0....   en   \n",
       "2     [[-0.07128145, 0.011230298, 0.045890186, -0.07...   en   \n",
       "3     [[-0.012562483, -0.03460731, 0.089639775, 0.02...   en   \n",
       "4     [[-0.04854836, 0.07415119, 0.044061035, -0.008...   en   \n",
       "...                                                 ...  ...   \n",
       "1805  [[-0.032125708, 0.005915861, 0.03515286, 0.006...   de   \n",
       "1806  [[0.045911647, 0.0021237172, -0.056985255, 0.0...   en   \n",
       "1807  [[0.027108321, -0.004789675, -0.036533337, 0.0...   en   \n",
       "1808  [[-0.0044380925, 0.0010670775, 0.06688552, 0.0...   en   \n",
       "1809  [[0.0336337, -0.0058375876, 0.08533424, 0.0237...   en   \n",
       "\n",
       "                                            text_tokens  \\\n",
       "0     ([Paris, the sixth century, the widow, the mer...   \n",
       "1     ([the volcano Anak Krakatau, Indonesia, it, a ...   \n",
       "2     ([Cassidy Curtis, Visual Designer, David Sales...   \n",
       "3     ([one thing, I, Germany, the bread, American W...   \n",
       "4     ([the Grind, this card trick, I, I, all the ti...   \n",
       "...                                                 ...   \n",
       "1805  ([der Union, der stark Kandidat, der Furcht, d...   \n",
       "1806  ([Ars Technica, today's Dealmaster, a return, ...   \n",
       "1807  ([a yemeni khamsiyat, a spanish real, (top rig...   \n",
       "1808  ([Bridgerton, the raunchy Regency costume dram...   \n",
       "1809  ([the hunt, a serial killer, who, gay man, Tor...   \n",
       "\n",
       "                                                 nc_vec  \n",
       "0     [[-0.0061701364, -0.012984723, -0.02264499, -0...  \n",
       "1     [[-0.0047265957, -0.011267428, -0.01635613, -0...  \n",
       "2     [[-0.005185811, -0.0008352126, -0.010343001, -...  \n",
       "3     [[0.005709256, -0.015197817, -0.002575722, -0....  \n",
       "4     [[0.0018794591, -0.0019065727, -0.024219586, -...  \n",
       "...                                                 ...  \n",
       "1805  [[-0.004311784, -0.00028916707, -0.020514684, ...  \n",
       "1806  [[-0.013846245, 0.010529164, -0.007516246, 0.0...  \n",
       "1807  [[0.008365323, -0.019968145, -0.02338454, -0.0...  \n",
       "1808  [[-0.011590819, -0.006641924, -0.014274846, -0...  \n",
       "1809  [[-0.0049721645, 0.00051928655, -0.0070937215,...  \n",
       "\n",
       "[1809 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "914d707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = get_modified_vectors(unlabeled_df.nc_vec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5497e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       113\n",
      "           1       0.38      0.19      0.25        16\n",
      "           2       0.49      0.83      0.61        23\n",
      "           3       0.35      0.45      0.39        33\n",
      "\n",
      "    accuracy                           0.61       185\n",
      "   macro avg       0.50      0.54      0.50       185\n",
      "weighted avg       0.64      0.61      0.61       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_model = get_performance_metrics(X_train_nc, y_train, X_test_nc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ebe575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df['milt_label'] = multi_model.predict(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_new = test_df[test_df['pred_label'].isin([0,1,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1770b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use = get_modified_vectors(train_df.doc_vec.values)\n",
    "X_test_use = get_modified_vectors(test_df.doc_vec.values)\n",
    "\n",
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values\n",
    "\n",
    "# y_train_new = np.array([val if val!=3 else 0 for val in y_train]).astype('int32')\n",
    "# y_test_new = np.array([val if val!=3 else 0 for val in y_test]).astype('int32')\n",
    "\n",
    "# y_train_tech = np.array([0 if val!=1 else 1 for val in y_train]).astype('int32')\n",
    "# y_test_tech = np.array([0 if val!=1 else 1 for val in y_test]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8606d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df_new = unlabeled_df[unlabeled_df['milt_label'].isin([0,1,3])]\n",
    "X_unlabeled_new = get_modified_vectors(unlabeled_df_new.nc_vec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cab777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bin_model.predict_proba(X_unlabeled_new)[:,1]\n",
    "unlabeled_df_new['tech_label'] = get_threshold_output(preds, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b8490be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1596\n",
       "3     176\n",
       "1      20\n",
       "2      17\n",
       "Name: milt_label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df['milt_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfb158a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(unlabeled_df_new['tech_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ccadc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_document_data(data, filepath):\n",
    "\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97137cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_data_dict = dict()\n",
    "\n",
    "for idx, row in unlabeled_df_new.iterrows():\n",
    "    \n",
    "    if row['tech_label'] == 1:\n",
    "        tech_data_dict[row['id']] = {\n",
    "            'page_id': row['id'],\n",
    "            'text': row['text']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff40a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "milt_data_dict = dict()\n",
    "\n",
    "for idx, row in unlabeled_df.iterrows():\n",
    "    \n",
    "    if row['milt_label'] == 2:\n",
    "        milt_data_dict[row['id']] = {\n",
    "            'page_id': row['id'],\n",
    "            'text': row['text']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b91ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_document_data(tech_data_dict, os.getcwd()+'/../json_data/technologie_document_data.json')\n",
    "write_document_data(milt_data_dict, os.getcwd()+'/../json_data/military_document_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43f89ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tech = np.array([0 if val!=1 else 1 for val in train_df.label.values]).astype('int32')\n",
    "\n",
    "X_test_new_nc = get_modified_vectors(test_df_new.nc_vec.values)\n",
    "y_test_new_tech = np.array([0 if val!=1 else 1 for val in test_df_new.label.values]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4ba12868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_adj = get_modified_vectors(test_df_new.adj_vec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d2b7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.10900000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87       134\n",
      "           1       0.24      0.75      0.37        12\n",
      "\n",
      "    accuracy                           0.79       146\n",
      "   macro avg       0.61      0.77      0.62       146\n",
      "weighted avg       0.91      0.79      0.83       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bin_model, threshold = get_performance_metrics(X_train_nc, y_train_tech, X_test_new_nc, y_test_new_tech, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "eac8e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.10500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86       134\n",
      "           1       0.19      0.58      0.29        12\n",
      "\n",
      "    accuracy                           0.76       146\n",
      "   macro avg       0.57      0.68      0.57       146\n",
      "weighted avg       0.89      0.76      0.81       146\n",
      "\n",
      "\n",
      "Training CV f1 score: 0\n",
      "Test F1-score: 0.28571428571428575\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_new_nc, y_train_new_tech, X_test_new_nc, y_test_new_tech, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "513f0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3529411764705882\n",
      "0.13100000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       169\n",
      "           1       0.13      0.25      0.17        16\n",
      "\n",
      "    accuracy                           0.79       185\n",
      "   macro avg       0.53      0.55      0.53       185\n",
      "weighted avg       0.85      0.79      0.82       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0\n",
      "Test F1-score: 0.1739130434782609\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_topic_use, y_train, X_test_topic_use, y_test_tech, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0240cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       113\n",
      "           1       0.43      0.19      0.26        16\n",
      "           2       0.45      0.78      0.57        23\n",
      "           3       0.38      0.42      0.40        33\n",
      "\n",
      "    accuracy                           0.63       185\n",
      "   macro avg       0.52      0.53      0.50       185\n",
      "weighted avg       0.66      0.63      0.63       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.41471200104976197\n",
      "Test F1-score: 0.4161490683229813\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_use, y_train, X_test_use, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba8373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6d3c907",
   "metadata": {},
   "source": [
    "### 2. Topic features testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f43b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_use_topic_score(doc_vec, topic):\n",
    "    \n",
    "    return cosine_similarity(doc_vec, topic_embeddings_dict[topic])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9bf40a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = ['Wirtschaft und Finanzen', 'Bildung', 'Politik', 'Tierreich', 'Rechtswissenschaften und Rechtsprechung', 'Gesundheit', 'Automobilbranche', 'Unterhaltung', 'Sport', 'Werbung', 'Technologie', 'Innovation', 'Militär', 'Quantencomputer', 'Swarm', 'Architecture', 'Forschnung', 'Drone', 'Autonomous', 'Modernisierung', 'Prototype', 'efficiency', 'Notebook', 'Angriff', 'Smartphone', 'Corona', 'Hacking', 'Kunden', 'Robot', 'Künstliche Intelligenz', 'smart', 'algorithmus', 'sensor', 'energy', 'digitalen', 'attack']\n",
    "# topic_list = ['Werbung', 'Technologie', 'Innovation', 'Militär', 'Quantencomputer', 'Swarm', 'Architecture', 'Forschnung', 'Drone', 'Autonomous', 'Modernisierung', 'Prototype', 'efficiency', 'Notebook', 'Angriff', 'Smartphone', 'Corona', 'Hacking', 'Kunden', 'Robot', 'Künstliche Intelligenz', 'smart', 'algorithmus', 'sensor', 'energy', 'digitalen', 'attack']\n",
    "\n",
    "topic_embeddings_dict = dict()\n",
    "for topic in topic_list:\n",
    "    topic_embeddings_dict[topic] = tf_model(topic)['outputs'].numpy()[0].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f0bd6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_col_list = []\n",
    "\n",
    "for topic in topic_list:\n",
    "    topic_col_name = topic.lower().replace(' ', '_') + '_sim'\n",
    "    topic_col_list.append(topic_col_name)\n",
    "    \n",
    "    train_df[topic_col_name] = train_df.apply(lambda x:get_use_topic_score(x['doc_vec'], topic), axis=1)\n",
    "    test_df[topic_col_name] = test_df.apply(lambda x:get_use_topic_score(x['doc_vec'], topic), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "53dce200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_topic_use = train_df[topic_col_list].values\n",
    "X_test_topic_use = test_df[topic_col_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3e9b7486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69       113\n",
      "           1       0.10      0.12      0.11        16\n",
      "           2       0.39      0.61      0.47        23\n",
      "           3       0.30      0.39      0.34        33\n",
      "\n",
      "    accuracy                           0.52       185\n",
      "   macro avg       0.40      0.43      0.40       185\n",
      "weighted avg       0.60      0.52      0.55       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.348627069009422\n",
      "Test F1-score: 0.29134218964727443\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_topic_use, y_train, X_test_topic_use, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e76857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16530b4b",
   "metadata": {},
   "source": [
    "### 3. Noun-chunks, Verb and Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e303d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d54e2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_data(text, lang):\n",
    "    \n",
    "    doc = None\n",
    "    \n",
    "    if lang == 'en':\n",
    "        doc = nlp_en(text)\n",
    "    elif lang == 'de':\n",
    "        doc = nlp_de(text)\n",
    "    elif lang == 'ko':\n",
    "        return None\n",
    "    \n",
    "    noun_phrases_list = []\n",
    "    verbs_list = []\n",
    "    adjs_list = []\n",
    "    \n",
    "    for nc in doc.noun_chunks:\n",
    "        noun_phrases_list.append(nc.lemma_) \n",
    "        \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adjs_list.append(token.lemma_)\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            verbs_list.append(token.lemma_)\n",
    "            \n",
    "    return (noun_phrases_list, verbs_list, adjs_list)\n",
    "\n",
    "def get_avg_token_vector(token_list):\n",
    "    \n",
    "    avg_token_vec = []\n",
    "    for token in token_list:\n",
    "        avg_token_vec.append(tf_model(token)['outputs'].numpy()[0].reshape(1, -1))\n",
    "        \n",
    "    return np.mean(avg_token_vec, axis=0)\n",
    "\n",
    "def get_mean_vector(vec_list):\n",
    "    return np.mean(vec_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6814545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    1284\n",
       "de     525\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "df495b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df['text_tokens'] = unlabeled_df.apply(lambda x:get_document_data(x['text'], x['lang']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "59418c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = unlabeled_df[unlabeled_df['lang'].isin(['en', 'de'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ccd5ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df.to_pickle(os.getcwd() + '/../dataframes/unlabeled_df_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e88521b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['text_tokens'] = train_df.apply(lambda x:get_document_data(x['text'], x['lang']), axis=1)\n",
    "# test_df['text_tokens'] = test_df.apply(lambda x:get_document_data(x['text'], x['lang']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72f4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['nc_vec'] = train_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][0]), axis=1)\n",
    "# train_df['verb_vec'] = train_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][1]), axis=1)\n",
    "# train_df['adj_vec'] = train_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][2]), axis=1)\n",
    "\n",
    "# test_df['nc_vec'] = test_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][0]), axis=1)\n",
    "# test_df['verb_vec'] = test_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][1]), axis=1)\n",
    "# test_df['adj_vec'] = test_df.apply(lambda x:get_avg_token_vector(x['text_tokens'][2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b18f99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_pickle(os.getcwd() + '/../dataframes/train_df_features.pkl')\n",
    "# test_df.to_pickle(os.getcwd() + '/../dataframes/test_df_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea72ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nc = get_modified_vectors(train_df.nc_vec.values)\n",
    "X_test_nc = get_modified_vectors(test_df.nc_vec.values)\n",
    "\n",
    "X_train_verb = get_modified_vectors(train_df.verb_vec.values)\n",
    "X_test_verb = get_modified_vectors(test_df.verb_vec.values)\n",
    "\n",
    "X_train_adj = get_modified_vectors(train_df.adj_vec.values)\n",
    "X_test_adj = get_modified_vectors(test_df.adj_vec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dab8c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_concatenate(vecs_1, vecs_2):\n",
    "    return np.concatenate((vecs_1,vecs_2), axis=1)\n",
    "\n",
    "def get_features_mean(vecs_1, vecs_2):\n",
    "    \n",
    "    return np.mean( (vecs_1,vecs_2), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e82793eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nc_ad = get_features_mean(X_train_nc, X_train_adj)\n",
    "X_test_nc_ad = get_features_mean(X_test_nc, X_test_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2714eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.63      0.71       113\n",
      "           1       0.30      0.19      0.23        16\n",
      "           2       0.45      0.83      0.58        23\n",
      "           3       0.35      0.48      0.41        33\n",
      "\n",
      "    accuracy                           0.59       185\n",
      "   macro avg       0.48      0.53      0.48       185\n",
      "weighted avg       0.64      0.59      0.60       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.42320817864428406\n",
      "Test F1-score: 0.40769230769230763\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_nc_ad, y_train, X_test_nc_ad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4830e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       113\n",
      "           1       0.38      0.19      0.25        16\n",
      "           2       0.49      0.83      0.61        23\n",
      "           3       0.35      0.45      0.39        33\n",
      "\n",
      "    accuracy                           0.61       185\n",
      "   macro avg       0.50      0.54      0.50       185\n",
      "weighted avg       0.64      0.61      0.61       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.3812573047867166\n",
      "Test F1-score: 0.4314516129032258\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_nc, y_train, X_test_nc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcf8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79       113\n",
      "           1       0.40      0.25      0.31        16\n",
      "           2       0.45      0.65      0.54        23\n",
      "           3       0.25      0.27      0.26        33\n",
      "\n",
      "    accuracy                           0.62       185\n",
      "   macro avg       0.48      0.48      0.47       185\n",
      "weighted avg       0.63      0.62      0.62       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.2532680007508382\n",
      "Test F1-score: 0.4217032967032967\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_verb, y_train, X_test_verb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad71439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       113\n",
      "           1       0.36      0.31      0.33        16\n",
      "           2       0.48      0.61      0.54        23\n",
      "           3       0.36      0.42      0.39        33\n",
      "\n",
      "    accuracy                           0.59       185\n",
      "   macro avg       0.49      0.51      0.49       185\n",
      "weighted avg       0.61      0.59      0.60       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.26448179271708677\n",
      "Test F1-score: 0.4358974358974359\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_train_adj, y_train, X_test_adj, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebe563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe2bf373",
   "metadata": {},
   "source": [
    "### 4. Combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98222b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage_one_models(X_1, X_2, y, model_1, model_2):\n",
    "    \n",
    "    model_1 = make_pipeline(StandardScaler(with_mean=False), model_1)\n",
    "    model_1.fit(X_1, y)\n",
    "    \n",
    "    model_2 = make_pipeline(StandardScaler(with_mean=False), model_2)\n",
    "    model_2.fit(X_2, y)  \n",
    "    \n",
    "    return model_1, model_2\n",
    "\n",
    "def create_stage_two_model(X, y, model_3):\n",
    "    \n",
    "    model_3 = make_pipeline(StandardScaler(with_mean=False), model_3)\n",
    "    model_3.fit(X, y) \n",
    "    \n",
    "    return model_3\n",
    "\n",
    "def get_transformed_features(model_1, model_2, X_1, X_2, y, y_flag=False):\n",
    "    \n",
    "    preds_1 = model_1.predict_proba(X_1)\n",
    "    preds_2 = model_2.predict_proba(X_2)\n",
    "    \n",
    "    combined_features = get_features_concatenate(preds_1, preds_2)\n",
    "    if not y_flag:\n",
    "        return combined_features\n",
    "    \n",
    "    return combined_features, y\n",
    "\n",
    "def get_finalmodel_pipeline(models, X_train_1, X_train_2, y_train, y_flag=False):\n",
    "    \n",
    "    model_1, model_2 = create_stage_one_models(X_train_1, X_train_2, y_train, models[0], models[1])\n",
    "    X, y = get_transformed_features(model_1, model_2, X_train_1, X_train_2, y_train, y_flag=True)\n",
    "    \n",
    "    model_3 = create_stage_two_model(X, y, models[2])\n",
    "    \n",
    "    return [model_1, model_2, model_3]\n",
    "\n",
    "def get_test_f1score_combined(models, X_test_1, X_test_2, y_test):\n",
    "    \n",
    "    X_test = get_transformed_features(models[0], models[1], X_test_1, X_test_2, y_test, y_flag=False)\n",
    "    preds = models[2].predict(X_test)\n",
    "    \n",
    "    f1_score = get_multi_class_metrics(y_test, preds, pr_flag=True)\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1e296c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation_combined(X_1, X_2, y, fold_cnt=5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=fold_cnt, shuffle=True, random_state=123)\n",
    "    f1_scores_list = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X_1, y):\n",
    "        \n",
    "        X_train_1, X_train_2, X_test_1, X_test_2 = X_1[train_idx], X_2[train_idx], X_1[test_idx], X_2[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        models = get_three_class_models()\n",
    "        models = get_finalmodel_pipeline(models, X_train_1, X_train_2, y_train)\n",
    "        \n",
    "        X_test = get_transformed_features(models[0], models[1], X_test_1, X_test_2, y_test, y_flag=False)\n",
    "        preds = models[2].predict(X_test)\n",
    "\n",
    "        f1_score = get_multi_class_metrics(y_test, preds, pr_flag=False)\n",
    "        f1_scores_list.append(f1_score)\n",
    "    \n",
    "    return sum(f1_scores_list)/fold_cnt\n",
    "\n",
    "def get_trained_model_combined(X_1, X_2, y):\n",
    "    \n",
    "    skf_f1score = perform_cross_validation_combined(X_1, X_2, y, fold_cnt=5)\n",
    "    \n",
    "    models = get_three_class_models()\n",
    "    models = get_finalmodel_pipeline(models, X_1, X_2, y)\n",
    "\n",
    "    return models, skf_f1score\n",
    "    \n",
    "\n",
    "def get_performance_metrics_combined(X_train_1, X_train_2, y_train, X_test_1, X_test_2, y_test):\n",
    "    \n",
    "    models, cv_score = get_trained_model_combined(X_train_1, X_train_2, y_train)\n",
    "    test_f1_score = get_test_f1score_combined(models, X_test_1, X_test_2, y_test)\n",
    "\n",
    "    print()\n",
    "    print(f'Training CV f1 score: {cv_score}')\n",
    "    print(f'Test F1-score: {test_f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fe62088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       113\n",
      "           1       1.00      0.12      0.22        16\n",
      "           2       0.44      0.17      0.25        23\n",
      "           3       0.38      0.36      0.37        33\n",
      "\n",
      "    accuracy                           0.63       185\n",
      "   macro avg       0.63      0.38      0.40       185\n",
      "weighted avg       0.63      0.63      0.59       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.24217057796005168\n",
      "Test F1-score: 0.2361111111111111\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics_combined(X_train_nc, X_train_verb, y_train, X_test_nc, X_test_verb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "58f87814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       113\n",
      "           1       1.00      0.06      0.12        16\n",
      "           2       0.60      0.26      0.36        23\n",
      "           3       0.33      0.24      0.28        33\n",
      "\n",
      "    accuracy                           0.62       185\n",
      "   macro avg       0.65      0.36      0.38       185\n",
      "weighted avg       0.63      0.62      0.57       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.31169002050580996\n",
      "Test F1-score: 0.24064171122994654\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics_combined(X_train_nc, X_train_adj, y_train, X_test_nc, X_test_adj, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b2bb1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       113\n",
      "           1       1.00      0.12      0.22        16\n",
      "           2       0.50      0.30      0.38        23\n",
      "           3       0.39      0.27      0.32        33\n",
      "\n",
      "    accuracy                           0.64       185\n",
      "   macro avg       0.65      0.40      0.43       185\n",
      "weighted avg       0.64      0.64      0.60       185\n",
      "\n",
      "\n",
      "Training CV f1 score: 0.3365809354044648\n",
      "Test F1-score: 0.3003003003003003\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics_combined(X_train_nc, X_train_use, y_train, X_test_nc, X_test_use, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
